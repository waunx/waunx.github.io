{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "NhsHZZwAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Xu Wan", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=NhsHZZwAAAAJ&citpid=13", "affiliation": "Zhejiang University", "organization": 1118375729466322660, "interests": ["Reinforcement Learning", "Large Language Model", "Large-scale Application"], "email_domain": "@zju.edu.cn", "homepage": "https://waunx.github.io/", "citedby": 61, "publications": {"NhsHZZwAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Physics-constrained vulnerability assessment of deep reinforcement learning-based SCOPF", "pub_year": "2022"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:d1gkVwhDpl0C", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17215931499721305639", "cites_id": ["17215931499721305639"]}, "NhsHZZwAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AdapSafe: Adaptive and Safe-Certified Deep Reinforcement Learning-Based Frequency Control for Carbon-neutral Power Systems", "pub_year": "2023"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:9yKSN-GCB0IC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1312377449083004227", "cites_id": ["1312377449083004227"]}, "NhsHZZwAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring the Vulnerability of Deep Reinforcement Learning-based Emergency Control for Low Carbon Power Systems", "pub_year": "2022"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:u-x6o8ySG0sC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2711575993861617869", "cites_id": ["2711575993861617869"]}, "NhsHZZwAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AdapSafe2: Prior-Free Safe-Certified Reinforcement Learning for Multi-Area Frequency Control", "pub_year": "2024"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:zYLM7Y9cAGgC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17223444715093073609", "cites_id": ["17223444715093073609"]}, "NhsHZZwAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AdapThink: Adaptive Thinking Preferences for Reasoning Language Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:Y0pCki6q_DkC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5470481485652151463", "cites_id": ["5470481485652151463"]}, "NhsHZZwAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Think Twice, Act Once: A Co-Evolution Framework of LLM and RL for Large-Scale Decision Making", "pub_year": "2025"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:W7OEmFMy1HYC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2732606574379815940", "cites_id": ["2732606574379815940"]}, "NhsHZZwAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SrSv: Integrating Sequential Rollouts with Sequential Value Estimation for Multi-agent Reinforcement Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:Tyk-4Ss8FVUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12559249513646685571", "cites_id": ["12559249513646685571"]}, "NhsHZZwAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Highly Transferable Adversarial Attack Against Deep-Reinforcement-Learning-Based Frequency Control", "pub_year": "2023"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:UeHWp8X0CEIC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12671524520284935502", "cites_id": ["12671524520284935502"]}, "NhsHZZwAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "IVMR suite: An Industrial-scale Virtual Machine Rescheduling Dataset and Benchmark for Elastic Cloud Service", "pub_year": "2025"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:eQOLeE2rZwMC", "num_citations": 0}, "NhsHZZwAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SAMG: Offline-to-Online Reinforcement Learning via State-Action-Conditional Offline Model Guidance", "pub_year": "2024"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:YsMSGLbcyi4C", "num_citations": 0}, "NhsHZZwAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Energy Consumption Analysis of Deep Reinforcement Learning"}, "filled": false, "author_pub_id": "NhsHZZwAAAAJ:WF5omc3nYNoC", "num_citations": 0}}, "citedby5y": 61, "hindex": 3, "hindex5y": 3, "i10index": 2, "i10index5y": 2, "cites_per_year": {"2022": 1, "2023": 16, "2024": 23, "2025": 21}, "updated": "2025-10-12 08:20:31.674240"}